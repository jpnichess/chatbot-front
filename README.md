# üåà Flexa AI ‚Äî Frontend

Interface web para o chatbot **Flexa**, constru√≠do com **React**, **TypeScript** e **Vite**.  
Este projeto consome o backend da Flexa AI para prover uma experi√™ncia de chat com streaming de respostas da IA baseada na API Gemini (Google).

---

## üöÄ Tecnologias

- [React](https://reactjs.org/)
- [TypeScript](https://www.typescriptlang.org/)
- [Vite](https://vitejs.dev/)
- [Axios](https://axios-http.com/) ‚Äì para chamadas HTTP
- [ESLint](https://eslint.org/) ‚Äì com suporte a TypeScript + React

---

## üì¶ Instala√ß√£o

```bash
# Clonar o reposit√≥rio
git clone https://github.com/jpnichess/Front-gpt.git
cd Front-gpt/

# Instalar depend√™ncias
npm install

Crie um arquivo .env.local na raiz do projeto com as vari√°veis:

VITE_FIREBASE_API_KEY=YOUR_FIREBASE_API_KEY
VITE_FIREBASE_AUTH_DOMAIN=YOUR_FIREBASE_AUTH_DOMAIN
VITE_FIREBASE_PROJECT_ID=YOUR_FIREBASE_PROJECT_ID
VITE_FIREBASE_STORAGE_BUCKET=YOUR_FIREBASE_STORAGE_BUCKET
VITE_FIREBASE_MESSAGING_SENDER_ID=YOUR_FIREBASE_MESSAGING_SENDER
VITE_FIREBASE_APP_ID=YOUR_FIREBASE_APP_ID
VITE_FIREBASE_MEASUREMENT_ID=YOUR_FIREBASE_MEASUREMENT_ID

üåê Integra√ß√£o com o Backend

A aplica√ß√£o se conecta a um backend que exp√µe os seguintes endpoints:

POST /stream-chat ‚Üí Envia mensagem e recebe resposta da IA via streaming

GET /history/:sessionId ‚Üí Retorna hist√≥rico de intera√ß√µes agrupadas

GET /history-detail/:conversationId ‚Üí Exibe detalhes de uma conversa espec√≠fica

